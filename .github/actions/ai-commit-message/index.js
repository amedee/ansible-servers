import * as core from "@actions/core";
import fetch from "node-fetch";

const PRIMARY_MODEL = "mistralai/devstral-small-2505:free";
const FALLBACK_MODEL = "moonshotai/kimi-dev-72b:free";
const URL = "https://openrouter.ai/api/v1/chat/completions";

const HTTP_TOO_MANY_REQUESTS = 429;
const HTTP_SERVICE_UNAVAILABLE = 503;

/**
 * Generate the prompt message body for OpenRouter API.
 */
function buildRequestBody(promptMessage, diff, model) {
  return {
    model,
    messages: [
      {
        role: "user",
        content: `${promptMessage}\n\n${diff}`,
      },
    ],
    temperature: 0.7,
  };
}

/**
 * Call the OpenRouter API with retry logic for transient errors.
 */
async function fetchCommitMessageWithRetry(
  body,
  token,
  retries = 5,
  delay = 1000,
) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      const response = await fetch(URL, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${token}`,
          "Content-Type": "application/json",
          "HTTP-Referer": `https://github.com/${process.env.GITHUB_REPOSITORY}`,
          "X-Title": "AI Commit Message",
        },
        body: JSON.stringify(body),
      });

      if (response.ok) {
        const json = await response.json();
        return json.choices?.[0]?.message?.content || "";
      }

      if (
        [HTTP_TOO_MANY_REQUESTS, HTTP_SERVICE_UNAVAILABLE].includes(
          response.status,
        )
      ) {
        const backoff = delay * Math.pow(2, attempt - 1);
        core.warning(
          `Attempt ${attempt} failed with ${response.status} ${response.statusText}, retrying in ${backoff}ms...`,
        );
        await new Promise((res) => setTimeout(res, backoff));
      } else {
        const text = await response.text();
        throw new Error(
          `OpenRouter API error: ${response.status} ${response.statusText} — ${text}`,
        );
      }
    } catch (error) {
      if (attempt === retries) {
        throw new Error(
          `OpenRouter API error after ${retries} attempts: ${error.message}`,
        );
      }
      await new Promise((res) =>
        setTimeout(res, delay * Math.pow(2, attempt - 1)),
      );
    }
  }
}

/**
 * Clean and truncate the commit message.
 */
function sanitizeMessage(message) {
  const cleaned = message.replace(/`/g, "");
  const lines = cleaned.split("\n");
  if (lines.length > 0) {
    lines[0] = lines[0].slice(0, 72);
  }
  return lines.join("\n");
}

/**
 * Try fetching commit message with a specified model.
 */
async function tryFetchWithModel(promptMessage, diffContent, token, model) {
  const body = buildRequestBody(promptMessage, diffContent, model);
  return await fetchCommitMessageWithRetry(body, token);
}

/**
 * Main entrypoint for the action.
 */
async function run() {
  const diffContent = core.getInput("diff_content");
  const promptMessage = core.getInput("prompt_content");
  const token = process.env.OPENROUTER_API_KEY;

  if (!token) {
    core.setFailed("❌ OPENROUTER_API_KEY is not set");
    return;
  }

  if (!diffContent) {
    core.setFailed("❌ diff_content input is empty");
    return;
  }

  try {
    // Try primary model first
    let message = await tryFetchWithModel(
      promptMessage,
      diffContent,
      token,
      PRIMARY_MODEL,
    );
    if (!message) throw new Error("No message generated by primary model");
    core.setOutput("message", sanitizeMessage(message));
  } catch (primaryError) {
    core.warning(
      `Primary model failed: ${primaryError.message}. Trying fallback model...`,
    );
    try {
      // Try fallback model
      let message = await tryFetchWithModel(
        promptMessage,
        diffContent,
        token,
        FALLBACK_MODEL,
      );
      if (!message) throw new Error("No message generated by fallback model");
      core.setOutput("message", sanitizeMessage(message));
    } catch (fallbackError) {
      core.setFailed(`Fallback model also failed: ${fallbackError.message}`);
    }
  }
}

run();
